{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime as datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"bpi2017_train.csv\", parse_dates = ['time:timestamp'])\n",
    "df_val = pd.read_csv(\"bpi2017_val.csv\", parse_dates = ['time:timestamp'])\n",
    "df_test = pd.read_csv(\"bpi2017_test.csv\", parse_dates = ['time:timestamp'])\n",
    "\n",
    "# The default name indicating the case ID is case:concept:name\n",
    "# concept:name is the event\n",
    "# time:timestamp is the corresponding timestamp\n",
    "# Load the datasets, sort them on case and consequently timestamp, then reset the index\n",
    "df_train = df_train.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "df_val = df_val.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "df_test = df_test.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "\n",
    "# Remove obsolete columns\n",
    "df_train.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "df_val.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "df_test.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate the Time Difference & Find Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum function to be used later\n",
    "def CumSum(lists):\n",
    "    # Returns the cumulative sum of a list\n",
    "    length = len(lists)\n",
    "    cu_list = [sum(lists[0: x: 1]) for x in range(0, length + 1)]\n",
    "    return cu_list[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference(df):\n",
    "    # Calculate time difference between each row\n",
    "    df['time_diff'] = df['time:timestamp'].diff().dt.total_seconds()\n",
    "    # Set the time difference of the 1st row to 0 as it's currently NaN\n",
    "    df.at[0, 'time_diff'] = 0\n",
    "    # Count number of steps per process\n",
    "    length_per_case_List = df.groupby(['case:concept:name'])['time_diff'].count().tolist()\n",
    "\n",
    "    # Using the cumulative sum we get all the positions that are a first step in a process\n",
    "    # And then the time difference can be set to 0\n",
    "    position_lst = CumSum(length_per_case_List)\n",
    "    for i in tqdm(position_lst):\n",
    "        df.at[i, 'time_diff'] = 0\n",
    "    # For Loop mysteriously creates an empty row at the end of the df, gotta delete it\n",
    "    df = df.iloc[: -1]\n",
    "\n",
    "    # Unzip the position list to get the number of each steps of each process, make that into a list\n",
    "    step_in_process = []\n",
    "    for x in tqdm(length_per_case_List):\n",
    "        for y in range(x):\n",
    "            step_in_process.append(y + 1)\n",
    "    # Assign position number to each row/process\n",
    "    df['position'] = step_in_process\n",
    "\n",
    "    # Find future time difference by shifting the current time difference\n",
    "    df['future_time_diff'] = df['time_diff'].shift(-1)\n",
    "    df.at[df.shape[0] - 1, 'future_time_diff'] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 16308/16308 [00:00<00:00, 65933.86it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 16308/16308 [00:00<00:00, 272514.96it/s]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 4078/4078 [00:00<00:00, 62322.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4078/4078 [00:00<00:00, 292062.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 751/751 [00:00<00:00, 53573.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 751/751 [00:00<00:00, 370622.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the above changes to all dataframes\n",
    "# The warnings are obsolete, it's because it uses .at which is considerably faster than .loc\n",
    "df_train = time_difference(df_train)\n",
    "df_val = time_difference(df_val)\n",
    "df_test = time_difference(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find Future Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_event(df):\n",
    "    # Find the next activity name by shifting the current event label\n",
    "    df['next:concept:name'] = df['concept:name'].shift(-1)\n",
    "    last_lst = [i - 1 for i in df[df['position'] == 1].index if i != 0]\n",
    "    # The next event label is 'Nothing' when the cycle is ended\n",
    "    df.at[df.shape[0] - 1, 'next:concept:name'] = 'Nothing'\n",
    "    for i in last_lst:\n",
    "        df.at[i, 'next:concept:name'] = 'Nothing'\n",
    "    return df\n",
    "\n",
    "df_train = next_event(df_train)\n",
    "df_val = next_event(df_val)\n",
    "df_test = next_event(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. New Feature: Weekend or Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekday(df):\n",
    "    # Get day of week like Monday, Tuesday, etc\n",
    "    df_day = pd.DataFrame(data = df['time:timestamp'].dt.dayofweek)\n",
    "    df_day.rename(columns = {'time:timestamp': 'day'}, inplace = True)\n",
    "    df['day'] = df_day['day']\n",
    "    return df\n",
    "\n",
    "df_train = add_weekday(df_train)\n",
    "df_val = add_weekday(df_val)\n",
    "df_test = add_weekday(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. New Feature: Working Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_working_hour(df):\n",
    "    # Get hour like 10, 15, etc\n",
    "    df_day = pd.DataFrame(data = df['time:timestamp'].dt.hour)\n",
    "    df_day.rename(columns = {'time:timestamp': 'hour'}, inplace = True)\n",
    "    df['hour'] = df_day['hour']\n",
    "    return df\n",
    "\n",
    "df_train = add_working_hour(df_train)\n",
    "df_val = add_working_hour(df_val)\n",
    "df_test = add_working_hour(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed_num = df_train[['case:RequestedAmount', 'position', 'day', 'hour']]\n",
    "X_train_processed_cat = df_train[['Action', 'concept:name', 'EventOrigin', 'lifecycle:transition', 'case:LoanGoal', 'case:ApplicationType']]\n",
    "y_train_1 = df_train[['future_time_diff']]\n",
    "y_train_2 = df_train[['next:concept:name']]\n",
    "\n",
    "# One-hot encoding on categorical data\n",
    "enc = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
    "transformed = enc.fit_transform(X_train_processed_cat)\n",
    "X_train_processed_cat = pd.DataFrame(transformed, columns = enc.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20201242\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\20201242\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['x1_A_Accepted', 'x1_A_Cancelled', 'x1_A_Create Application',\n",
       "       'x1_A_Denied', 'x1_A_Validating', 'x1_O_Accepted', 'x1_O_Create Offer',\n",
       "       'x1_O_Created', 'x1_W_Assess potential fraud', 'x1_W_Call after offers',\n",
       "       'x1_W_Call incomplete files', 'x1_W_Complete application',\n",
       "       'x1_W_Validate application', 'x2_Offer', 'x3_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb = SelectKBest(score_func = f_classif, k = 15)\n",
    "skb.fit_transform(X_train_processed_cat, y_train_2)\n",
    "cols = skb.get_support(indices = True)\n",
    "features_df_new = X_train_processed_cat.iloc[:, cols]\n",
    "features_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20201242\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['position', 'day', 'hour'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb = SelectKBest(score_func = f_classif, k = 3)\n",
    "skb.fit_transform(X_train_processed_num, y_train_2)\n",
    "cols = skb.get_support(indices = True)\n",
    "features_df_new = X_train_processed_num.iloc[:, cols]\n",
    "features_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20201242\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['x0_Created', 'x0_Deleted', 'x0_Obtained', 'x0_Released',\n",
       "       'x0_statechange', 'x1_W_Call after offers', 'x2_Application',\n",
       "       'x2_Offer', 'x2_Workflow', 'x3_ate_abort', 'x3_complete', 'x3_resume',\n",
       "       'x3_schedule', 'x3_start', 'x3_suspend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb = SelectKBest(score_func = f_regression, k = 15)\n",
    "skb.fit_transform(X_train_processed_cat, y_train_1)\n",
    "cols = skb.get_support(indices = True)\n",
    "features_df_new = X_train_processed_cat.iloc[:, cols]\n",
    "features_df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20201242\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['case:RequestedAmount', 'position', 'day'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb = SelectKBest(score_func = f_regression, k = 3)\n",
    "skb.fit_transform(X_train_processed_num, y_train_1)\n",
    "cols = skb.get_support(indices = True)\n",
    "features_df_new = X_train_processed_num.iloc[:, cols]\n",
    "features_df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 776130/776130 [12:12<00:00, 1058.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8459"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove outlier on both training and validation data\n",
    "df_all = pd.concat([df_train, df_val])\n",
    "df_all = df_all.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "\n",
    "def find_outlier(process_name, df):\n",
    "    # Remove outlier having time_diff larger than mean +- 3 * SD\n",
    "    df_needed = df[(df['concept:name'] == process_name)]\n",
    "    mean_value = df_needed['time_diff'].mean()\n",
    "    std_value = df_needed['time_diff'].std()\n",
    "    upper_bound =  mean_value + 3 * std_value\n",
    "    lower_bound = mean_value - 3 * std_value\n",
    "    new_df = df_needed[(df_needed['time_diff'] < lower_bound) | (df_needed['time_diff'] > upper_bound)]\n",
    "    # Return case id that has at least 1 process as outlier\n",
    "    return new_df['case:concept:name'].tolist()\n",
    "\n",
    "outlier_lst = []\n",
    "# i refers to the position number\n",
    "for i in tqdm(range(2, len(df_all['position'].tolist()))):\n",
    "    df_pos = df_all[df_all['position'] == i]\n",
    "    # a refers to the concept name per position number\n",
    "    for a in df_pos['concept:name'].unique().tolist():\n",
    "        small_outlier_lst = find_outlier(a, df_pos)\n",
    "        outlier_lst = list(set(outlier_lst + small_outlier_lst))\n",
    "\n",
    "len(outlier_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all outliers\n",
    "df_filtered = df_all[~df_all['case:concept:name'].isin(outlier_lst)]\n",
    "final_all_train = sorted(df_filtered['case:concept:name'].unique().tolist())\n",
    "\n",
    "# Split training and validation dataset\n",
    "final_train, final_val = train_test_split(final_all_train, test_size = 0.2)\n",
    "df_train = df_filtered[df_filtered['case:concept:name'].isin(final_train)]\n",
    "df_val = df_filtered[df_filtered['case:concept:name'].isin(final_val)]\n",
    "\n",
    "# To make sure, again sort the datasets on case and consequently timestamp, then reset the index\n",
    "df_train = df_train.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "df_val = df_val.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Var for time: lifecycle:transition, Action, concept:name, EventOrigin, day, position, case:RequestedAmount\n",
    "# Var for label: concept:name, lifecycle:transition, EventOrigin, Action, day, position, hour\n",
    "df_train = df_train[['case:concept:name', 'next:concept:name', 'time:timestamp', 'time_diff', \n",
    "                     'future_time_diff', 'concept:name', 'lifecycle:transition', \n",
    "                     'EventOrigin', 'Action', 'day', 'position', 'hour', 'case:RequestedAmount']]\n",
    "df_val = df_val[['case:concept:name', 'next:concept:name', 'time:timestamp', 'time_diff', \n",
    "                     'future_time_diff', 'concept:name', 'lifecycle:transition', \n",
    "                     'EventOrigin', 'Action', 'day', 'position', 'hour', 'case:RequestedAmount']]\n",
    "df_test = df_test[['case:concept:name', 'next:concept:name', 'time:timestamp', 'time_diff', \n",
    "                     'future_time_diff', 'concept:name', 'lifecycle:transition', \n",
    "                     'EventOrigin', 'Action', 'day', 'position', 'hour', 'case:RequestedAmount']]\n",
    "df_train.to_csv('bpi2017_train_filtered.csv', index = False)\n",
    "df_val.to_csv('bpi2017_val_filtered.csv', index = False)\n",
    "df_test.to_csv('bpi2017_test_filtered.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
