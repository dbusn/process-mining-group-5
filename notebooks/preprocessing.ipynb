{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime as datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"bpi2017_train.csv\", parse_dates = ['time:timestamp'])\n",
    "df_val = pd.read_csv(\"bpi2017_val.csv\", parse_dates = ['time:timestamp'])\n",
    "df_test = pd.read_csv(\"bpi2017_test.csv\", parse_dates = ['time:timestamp'])\n",
    "\n",
    "# The default name indicating the case ID is case:concept:name\n",
    "# concept:name is the event\n",
    "# time:timestamp is the corresponding timestamp\n",
    "# Load the datasets, sort them on case and consequently timestamp, then reset the index\n",
    "df_train = df_train.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index()\n",
    "df_val = df_val.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index()\n",
    "df_test = df_test.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index()\n",
    "\n",
    "# Remove obsolete columns\n",
    "df_train = df_train[['case:concept:name', 'concept:name', 'time:timestamp']]\n",
    "df_val = df_val[['case:concept:name', 'concept:name', 'time:timestamp']]\n",
    "df_test = df_test[['case:concept:name', 'concept:name', 'time:timestamp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculate the Time Difference & Find Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum function to be used later\n",
    "def CumSum(lists):\n",
    "    # Returns the cumulative sum of a list\n",
    "    length = len(lists)\n",
    "    cu_list = [sum(lists[0: x: 1]) for x in range(0, length + 1)]\n",
    "    return cu_list[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference(df):\n",
    "    # Calculate time difference between each row\n",
    "    df['time_diff'] = df['time:timestamp'].diff().dt.total_seconds()\n",
    "    # Set the time difference of the 1st row to 0 as it's currently NaN\n",
    "    df.at[0, 'time_diff'] = 0\n",
    "    # Count number of steps per process\n",
    "    length_per_case_List = df.groupby(['case:concept:name'])['time_diff'].count().tolist()\n",
    "\n",
    "    # Using the cumulative sum we get all the positions that are a first step in a process\n",
    "    # And then the time difference can be set to 0\n",
    "    position_lst = CumSum(length_per_case_List)\n",
    "    for i in tqdm(position_lst):\n",
    "        df.at[i, 'time_diff'] = 0\n",
    "    # For Loop mysteriously creates an empty row at the end of the df, gotta delete it\n",
    "    df = df.iloc[: -1]\n",
    "\n",
    "    # Unzip the position list to get the number of each steps of each process, make that into a list\n",
    "    step_in_process = []\n",
    "    for x in tqdm(length_per_case_List):\n",
    "        for y in range(x):\n",
    "            step_in_process.append(y + 1)\n",
    "    # Assign position number to each row/process\n",
    "    df['position'] = step_in_process\n",
    "\n",
    "    # Find future time difference by shifting the current time difference\n",
    "    df['future_time_diff'] = df['time_diff'].shift(-1)\n",
    "    df.at[df.shape[0] - 1, 'future_time_diff'] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 16308/16308 [00:00<00:00, 111197.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 16308/16308 [00:00<00:00, 297117.94it/s]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4078/4078 [00:00<00:00, 107470.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4078/4078 [00:00<00:00, 314129.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 751/751 [00:00<00:00, 107067.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 751/751 [00:00<00:00, 251049.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply the above changes to all dataframes\n",
    "# The warnings are obsolete, it's because it uses .at which is considerably faster than .loc\n",
    "df_train = time_difference(df_train)\n",
    "df_val = time_difference(df_val)\n",
    "df_test = time_difference(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find Future Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_event(df):\n",
    "    # Find the next activity name by shifting the current event label\n",
    "    df['next:concept:name'] = df['concept:name'].shift(-1)\n",
    "    last_lst = [i - 1 for i in df[df['position'] == 1].index if i != 0]\n",
    "    # The next event label is 'Nothing' when the cycle is ended\n",
    "    df.at[df.shape[0] - 1, 'next:concept:name'] = 'Nothing'\n",
    "    for i in last_lst:\n",
    "        df.at[i, 'next:concept:name'] = 'Nothing'\n",
    "    return df\n",
    "\n",
    "df_train = next_event(df_train)\n",
    "df_val = next_event(df_val)\n",
    "df_test = next_event(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 776130/776130 [12:19<00:00, 1050.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8459"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove outlier on both training and validation data\n",
    "df_all = pd.concat([df_train, df_val])\n",
    "df_all = df_all.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "\n",
    "def find_outlier(process_name, df):\n",
    "    # Remove outlier having time_diff larger than mean +- 3 * SD\n",
    "    df_needed = df[(df['concept:name'] == process_name)]\n",
    "    mean_value = df_needed['time_diff'].mean()\n",
    "    std_value = df_needed['time_diff'].std()\n",
    "    upper_bound =  mean_value + 3 * std_value\n",
    "    lower_bound = mean_value - 3 * std_value\n",
    "    new_df = df_needed[(df_needed['time_diff'] < lower_bound) | (df_needed['time_diff'] > upper_bound)]\n",
    "    # Return case id that has at least 1 process as outlier\n",
    "    return new_df['case:concept:name'].tolist()\n",
    "\n",
    "outlier_lst = []\n",
    "# i refers to the position number\n",
    "for i in tqdm(range(2, len(df_all['position'].tolist()))):\n",
    "    df_pos = df_all[df_all['position'] == i]\n",
    "    # a refers to the concept name per position number\n",
    "    for a in df_pos['concept:name'].unique().tolist():\n",
    "        small_outlier_lst = find_outlier(a, df_pos)\n",
    "        outlier_lst = list(set(outlier_lst + small_outlier_lst))\n",
    "\n",
    "len(outlier_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all outliers\n",
    "df_filtered = df_all[~df_all['case:concept:name'].isin(outlier_lst)]\n",
    "final_all_train = sorted(df_filtered['case:concept:name'].unique().tolist())\n",
    "\n",
    "# Split training and validation dataset\n",
    "final_train, final_val = train_test_split(final_all_train, test_size = 0.2)\n",
    "df_train = df_filtered[df_filtered['case:concept:name'].isin(final_train)]\n",
    "df_val = df_filtered[df_filtered['case:concept:name'].isin(final_val)]\n",
    "\n",
    "# To make sure, again sort the datasets on case and consequently timestamp, then reset the index\n",
    "df_train = df_train.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "df_val = df_val.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('bpi2017_train_filtered.csv', index = False)\n",
    "df_val.to_csv('bpi2017_val_filtered.csv', index = False)\n",
    "df_test.to_csv('bpi2017_test_filtered.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
