{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0aee2f",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83849ae2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import datetime as datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c15c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('bpi2017_test.csv')\n",
    "df_train = pd.read_csv(\"bpi2017_train.csv\")\n",
    "df_val = pd.read_csv(\"bpi2017_val.csv\")\n",
    "\n",
    "df_test['time:timestamp'] = pd.to_datetime(df_test['time:timestamp'])\n",
    "df_train['time:timestamp'] = pd.to_datetime(df_train['time:timestamp'])\n",
    "df_val['time:timestamp'] = pd.to_datetime(df_val['time:timestamp'])\n",
    "\n",
    "# df_val = df_val.rename(columns = {\"concept:name\": 'event', \"case:concept:name\": 'case', \"org:resource\": 'role'})\n",
    "# df_test = df_val.rename(columns = {\"concept:name\": 'event', \"case:concept:name\": 'case', \"org:resource\": 'role'})\n",
    "# df_train = df_val.rename(columns = {\"concept:name\": 'event', \"case:concept:name\": 'case', \"org:resource\": 'role'})\n",
    "\n",
    "\n",
    "df_train = df_train.drop(columns=['Unnamed: 0'])\n",
    "df_val = df_val.drop(columns=[\"Unnamed: 0\"])\n",
    "df_test = df_test.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3d63e",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = ['EventOrigin', 'Action', 'lifecycle:transition']\n",
    "df_train = pd.get_dummies(df_train, columns=encoded_cols, prefix=[\"EventOrigin_is\", \"action_is\", 'lifecycle:transition_is'])\n",
    "df_val = pd.get_dummies(df_val, columns=encoded_cols, prefix=[\"EventOrigin_is\", \"action_is\", 'lifecycle:transition_is'])\n",
    "df_test = pd.get_dummies(df_test, columns=encoded_cols, prefix=[\"EventOrigin_is\", \"action_is\", 'lifecycle:transition_is'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc30c307",
   "metadata": {},
   "source": [
    "# Creating additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a826089",
   "metadata": {},
   "source": [
    "### Next and past activity timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_past_activity(df):\n",
    "    temp = df['time:timestamp']\n",
    "    next_activity = []\n",
    "    for i in range(len(temp)-1):\n",
    "        next_activity.append(temp[i+1])\n",
    "\n",
    "    df['next_activity_delta_t'] = pd.Series(next_activity) - df['time:timestamp']\n",
    "    df['past_activity_delta_t'] = df['time:timestamp'] - pd.Series(next_activity)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0592dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative sum function to be used later\n",
    "def CumSum(lists):\n",
    "    # Returns the cumulative sum of a list\n",
    "    length = len(lists)\n",
    "    cu_list = [sum(lists[0: x: 1]) for x in range(0, length + 1)]\n",
    "    return cu_list[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a2b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_event(df):\n",
    "    # Find the next activity name by shifting the current event label\n",
    "    df['next:concept:name'] = df['concept:name'].shift(-1)\n",
    "    last_lst = [i - 1 for i in df[df['position'] == 1].index if i != 0]\n",
    "    # The next event label is 'Nothing' when the cycle is ended\n",
    "    df.at[df.shape[0] - 1, 'next:concept:name'] = 'Nothing'\n",
    "    for i in last_lst:\n",
    "        df.at[i, 'next:concept:name'] = 'Nothing'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcd02f3",
   "metadata": {},
   "source": [
    "### Time difference feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5770091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference(df):\n",
    "    # Calculate time difference between each row\n",
    "    df['time_diff'] = df['time:timestamp'].diff().dt.total_seconds()\n",
    "    # Set the time difference of the 1st row to 0 as it's currently NaN\n",
    "    df.at[0, 'time_diff'] = 0\n",
    "    # Count number of steps per process\n",
    "    length_per_case_List = df.groupby(['case:concept:name'])['time_diff'].count().tolist()\n",
    "\n",
    "    # Using the cumulative sum we get all the positions that are a first step in a process\n",
    "    # And then the time difference can be set to 0\n",
    "    position_lst = CumSum(length_per_case_List)\n",
    "    for i in tqdm(position_lst):\n",
    "        df.at[i, 'time_diff'] = 0\n",
    "    # For Loop mysteriously creates an empty row at the end of the df, gotta delete it\n",
    "    df = df.iloc[: -1]\n",
    "\n",
    "    # Unzip the position list to get the number of each steps of each process, make that into a list\n",
    "    step_in_process = []\n",
    "    for x in tqdm(length_per_case_List):\n",
    "        for y in range(x):\n",
    "            step_in_process.append(y + 1)\n",
    "    # Assign position number to each row/process\n",
    "    df['position'] = step_in_process\n",
    "\n",
    "    # Find future time difference by shifting the current time difference\n",
    "    df['future_time_diff'] = df['time_diff'].shift(-1)\n",
    "    df.at[df.shape[0] - 1, 'future_time_diff'] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278891eb",
   "metadata": {},
   "source": [
    "### Weekday feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekday(df):\n",
    "    # Get day of week like Monday, Tuesday, etc\n",
    "    df_day = pd.DataFrame(data = df['time:timestamp'].dt.dayofweek)\n",
    "    df_day.rename(columns = {'time:timestamp': 'day'}, inplace = True)\n",
    "    df['day'] = df_day['day']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e39eb1",
   "metadata": {},
   "source": [
    "### Working hour feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d48228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_working_hour(df):\n",
    "    # Get hour like 10, 15, etc\n",
    "    df_day = pd.DataFrame(data = df['time:timestamp'].dt.hour)\n",
    "    df_day.rename(columns = {'time:timestamp': 'hour'}, inplace = True)\n",
    "    df['hour'] = df_day['hour']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85567bf1",
   "metadata": {},
   "source": [
    "### Timestamp parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(df):\n",
    "    temp = df[\"time:timestamp\"]\n",
    "    day_of_month = []\n",
    "    month_no = []\n",
    "    quarters = []\n",
    "    week = []\n",
    "    hour = []\n",
    "    seconds = []\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        day_of_month.append(temp[i].day)\n",
    "        month_no.append(temp[i].month)\n",
    "        quarters.append(temp[i].quarter)\n",
    "        week.append(temp[i].week)\n",
    "        hour.append(temp[i].hour)\n",
    "        seconds.append(temp[i].second)\n",
    "\n",
    "    df['day_of_month'] = pd.Series(day_of_month)\n",
    "    df['month_no'] = pd.Series(month_no)\n",
    "    df['quarter'] = pd.Series(quarters)\n",
    "    df['week'] = pd.Series(week)\n",
    "    df['hour'] = pd.Series(hour)\n",
    "    df['second'] = pd.Series(seconds)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ddd38",
   "metadata": {},
   "source": [
    "### Time difference normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_delta_t(df):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "\n",
    "    df['norm_next_activity_delta'] = min_max_scaler.fit_transform(np.array(df[\"next_activity_delta_t\"]).reshape(-1,1))\n",
    "    df['norm_past_activity_delta'] = min_max_scaler.fit_transform(np.array(df[\"past_activity_delta_t\"]).reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a17a8",
   "metadata": {},
   "source": [
    "# Applying functions on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50733841",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = time_difference(df_train)\n",
    "df_val = time_difference(df_val)\n",
    "df_test = time_difference(df_test)\n",
    "\n",
    "df_train = parse_timestamp(df_train)\n",
    "df_val = parse_timestamp(df_val)\n",
    "df_test = parse_timestamp(df_test)\n",
    "\n",
    "df_train = next_past_activity(df_train)\n",
    "df_val = next_past_activity(df_val)\n",
    "df_test = next_past_activity(df_test)\n",
    "\n",
    "df_train = normalize_delta_t(df_train)\n",
    "df_val = normalize_delta_t(df_val)\n",
    "df_test = normalize_delta_t(df_test)\n",
    "\n",
    "df_train = next_event(df_train)\n",
    "df_val = next_event(df_val)\n",
    "df_test = next_event(df_test)\n",
    "\n",
    "df_train = add_weekday(df_train)\n",
    "df_val = add_weekday(df_val)\n",
    "df_test = add_weekday(df_test)\n",
    "\n",
    "df_train = add_working_hour(df_train)\n",
    "df_val = add_working_hour(df_val)\n",
    "df_test = add_working_hour(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94ffe1",
   "metadata": {},
   "source": [
    "## Locating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a77232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outlier on both training and validation data\n",
    "df_all = pd.concat([df_train, df_val])\n",
    "df_all = df_all.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "\n",
    "def find_outlier(process_name, df):\n",
    "    # Remove outlier having time_diff larger than mean +- 3 * SD\n",
    "    df_needed = df[(df['concept:name'] == process_name)]\n",
    "    mean_value = df_needed['time_diff'].mean()\n",
    "    std_value = df_needed['time_diff'].std()\n",
    "    upper_bound =  mean_value + 3 * std_value\n",
    "    lower_bound = mean_value - 3 * std_value\n",
    "    new_df = df_needed[(df_needed['time_diff'] < lower_bound) | (df_needed['time_diff'] > upper_bound)]\n",
    "    # Return case id that has at least 1 process as outlier\n",
    "    return new_df['case:concept:name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64add03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_lst = []\n",
    "# i refers to the position number\n",
    "for i in tqdm(range(2, len(df_all['position'].tolist()))):\n",
    "    df_pos = df_all[df_all['position'] == i]\n",
    "    # a refers to the concept name per position number\n",
    "    for a in df_pos['concept:name'].unique().tolist():\n",
    "        small_outlier_lst = find_outlier(a, df_pos)\n",
    "        outlier_lst = list(set(outlier_lst + small_outlier_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8572bb",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all outliers\n",
    "df_filtered = df_all[~df_all['case:concept:name'].isin(outlier_lst)]\n",
    "final_all_train = sorted(df_filtered['case:concept:name'].unique().tolist())\n",
    "\n",
    "# Split training and validation dataset\n",
    "final_train, final_val = train_test_split(final_all_train, test_size = 0.2)\n",
    "df_train = df_filtered[df_filtered['case:concept:name'].isin(final_train)]\n",
    "df_val = df_filtered[df_filtered['case:concept:name'].isin(final_val)]\n",
    "\n",
    "# To make sure, again sort the datasets on case and consequently timestamp, then reset the index\n",
    "df_train = df_train.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)\n",
    "df_val = df_val.sort_values(by = ['case:concept:name', 'time:timestamp']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ff0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7720ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0879b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5cc74",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e966850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('bci2017_train.csv', index=False)\n",
    "df_test.to_csv(\"bci2017_test\", index=False)\n",
    "df_val.to_csv(\"bci2017_val\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac8fb13fc3bee92f824433c9c23003f97fe6b9b9d15b38f1d3099836166493d1"
  },
  "kernelspec": {
   "display_name": "Python (process-mining)",
   "language": "python",
   "name": "dbl-process-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
